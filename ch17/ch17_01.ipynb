{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "KoBERT"
      ],
      "metadata": {
        "id": "I9gQ3gP62ZcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "G2dIQFDy5LRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
      ],
      "metadata": {
        "id": "q4z73QTC3s3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
        "tokenizer.encode(\"한국어 모델을 공유합니다.\")"
      ],
      "metadata": {
        "id": "MrRItwWK4vyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer('한국어 모델을 공유합니다.')"
      ],
      "metadata": {
        "id": "fHcNdKPf6YoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertModel\n",
        "model = BertModel.from_pretrained('skt/kobert-base-v1')\n",
        "text = \"한국어 모델을 공유합니다.\"\n",
        "inputs = tokenizer.batch_encode_plus([text])\n",
        "out = model(input_ids = torch.tensor(inputs['input_ids']),\n",
        "              attention_mask = torch.tensor(inputs['attention_mask']))\n",
        "out.pooler_output.shape"
      ],
      "metadata": {
        "id": "tVRLYpSS2ba_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋클래스\n",
        "import torch\n",
        "class OurDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "    self.encodings = encodings\n",
        "    self.labels = labels\n",
        "  def __getitem__(self, idx):\n",
        "    item = {key: torch.tensor(val[idx].clone().detach()) for key, val in self.encodings.items()}\n",
        "    item['labels'] = torch.tensor(self.labels[idx])\n",
        "    return item\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n"
      ],
      "metadata": {
        "id": "WuuCKmL66_6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드 및 분할(여기서는 성능상 일부 데이터만 사용)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 데이터셋 로드\n",
        "url = \"https://drive.google.com/uc?id=1KOKgZ4qCg49bgj1QNTwk1Vd29soeB27o\"\n",
        "df = pd.read_csv(url)\n",
        "print(len(df))\n",
        "df = df.sample(frac=0.1)\n",
        "print(len(df))\n",
        "X = df.review.tolist()\n",
        "y = (df.rating >= 6).values.astype(int)\n",
        "x_,x_test,y_,y_test = train_test_split(X,y,stratify=y,random_state=42,test_size=0.2)\n",
        "x_train,x_val,y_train,y_val = train_test_split(x_,y_,stratify=y_, random_state=42,test_size=0.2)"
      ],
      "metadata": {
        "id": "eGt5Er_I-VHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# 토큰화\n",
        "train_input = tokenizer(x_train, truncation=True, padding=True,return_tensors='pt')\n",
        "val_input = tokenizer(x_val, truncation=True, padding=True, max_length=512,return_tensors='pt')\n",
        "test_input = tokenizer(x_test, truncation=True, padding=True, max_length=512,return_tensors='pt')\n",
        "# DataSet 생성\n",
        "# 데이터로더 생성\n",
        "# KoBERT 한국어 전용 모델 로드\n",
        "# BERT를 포함한 신경망 모델\n",
        "# 학습 - 미니배치\n",
        "  # device\n",
        "  # optimize\n",
        "  # 학습 스케줄러\n",
        "  # epoch수만큼 loop"
      ],
      "metadata": {
        "id": "OxrAllZS8rM_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}