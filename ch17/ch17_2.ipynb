{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BpK4bMbFuC0E"
      },
      "outputs": [],
      "source": [
        "# Transformer 는 encoder -> decoder\n",
        "# encoder 를 이용해서 만든 언어모델 BERT : 감성분류, 스펨, 개체명인식, 유사도측정 --> 추출\n",
        "# decoder 를 이용해서 만든 언어모델 GPT : 언어 추론 요약, QA 챗봇  --> 생성"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bert가 잘하는 것 : 분류, 빈칸 추론, 문장 임베딩"
      ],
      "metadata": {
        "id": "4lBy5odBvyzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
      ],
      "metadata": {
        "id": "ijLggH6RwPUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')"
      ],
      "metadata": {
        "id": "VmEhOKGRvVXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForMaskedLM\n",
        "model = BertForMaskedLM.from_pretrained('skt/kobert-base-v1')\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "be7eOoz2wqc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 상식 추론\n",
        "import torch\n",
        "text = '한국의 수도는 [MASK]입니다.'\n",
        "input_ids = tokenizer.encode(text,return_tensors='pt')\n",
        "mask_token_index = torch.where(input_ids == tokenizer.mask_token_id)[1]\n",
        "# 추론\n",
        "with torch.no_grad():\n",
        "  outputs = model(input_ids)\n",
        "  predictions = outputs.logits\n",
        "print( predictions.shape )\n",
        "\n",
        "print(predictions[0,mask_token_index,:])\n",
        "masked_prediction = predictions[0,mask_token_index,:].topk(5)\n",
        "for i, index_t in enumerate(masked_prediction.indices[0]):\n",
        "  index = index_t.item()\n",
        "  print(tokenizer.decode([index]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iGnPvyLxAge",
        "outputId": "0f794ab2-9a5a-4165-c0ff-639f021a5ed3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 9, 8002])\n",
            "tensor([[-0.8262, -0.2269,  1.4582,  ..., -0.6751, -1.3650, -1.6105]])\n",
            "바이오\n",
            "않을까\n",
            "승진\n",
            "계절\n",
            "즐거운\n"
          ]
        }
      ]
    }
  ]
}