{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROOrxwYy6My5",
        "outputId": "85539560-3533-437b-c12f-4518f76994f5"
      },
      "outputs": [],
      "source": [
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMBRltXI5zLP"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 필수 라이브러리 임포트\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Transformers 라이브러리\n",
        "from transformers import (\n",
        "    pipeline,                              # 고수준 API - 가장 쉬운 방법\n",
        "    AutoTokenizer,                         # 자동 토크나이저\n",
        "    AutoModelForQuestionAnswering,         # QA 모델 자동 로더\n",
        "    DistilBertTokenizerFast,              # DistilBERT 고속 토크나이저\n",
        "    DistilBertForQuestionAnswering,        # DistilBERT QA 모델\n",
        "    ElectraTokenizer,                      # ELECTRA 토크나이저 (한글)\n",
        "    ElectraForQuestionAnswering,           # ELECTRA QA 모델 (한글)\n",
        "    DefaultDataCollator,                   # 기본 데이터 콜레이터\n",
        "    TrainingArguments,                     # 학습 하이퍼파라미터\n",
        "    Trainer,                               # 범용 트레이너\n",
        ")\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsisx17i53k9",
        "outputId": "6aae3d17-e0b7-4766-cb35-0ee943013995"
      },
      "outputs": [],
      "source": [
        "question_answer = pipeline(\"question-answering\",model = 'distilbert-base-cased-distilled-squad')\n",
        "\n",
        "context = \"\"\"Text mining, also referred to as text data mining (abbr.: TDM), similar to text analytics,\n",
        "is the process of deriving high-quality information from text. It involves\n",
        "\"the discovery by computer of new, previously unknown information,\n",
        "by automatically extracting information from different written resources.\"\n",
        "Written resources may include websites, books, emails, reviews, and articles.\n",
        "High-quality information is typically obtained by devising patterns and trends\n",
        "by means such as statistical pattern learning. According to Hotho et al. (2005)\n",
        "we can distinguish between three different perspectives of text mining:\n",
        "information extraction, data mining, and a KDD (Knowledge Discovery in Databases) process.\"\"\"\n",
        "\n",
        "question1 = \"What is text mining?\"\n",
        "question2 = \"What are the perspectives of text mining?\"\n",
        "\n",
        "# 질의 응답 수행\n",
        "answer1 = question_answer(context=context, question=question1)\n",
        "answer2 = question_answer(context=context, question=question2)\n",
        "if answer1['score'] < 0.1:\n",
        "  print(f'answer1 : 답변 없음')\n",
        "else:\n",
        "  print(f\"answer1 : {answer1['answer']}\")\n",
        "if answer2['score'] < 0.1:\n",
        "  print(f'answer2 : 답변 없음')\n",
        "else:\n",
        "  print(f\"answer2 : {answer2['answer']}\")\n",
        "\n",
        "# AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "inputs = tokenizer(question1, context, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "start_score = outputs.start_logits\n",
        "end_score  = outputs.end_logits\n",
        "answer_start = torch.argmax(start_score)\n",
        "answer_end = torch.argmax(end_score)\n",
        "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end+1]))\n",
        "print(f\"answer1 : {answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR_U591M8FBN",
        "outputId": "22682303-d518-499e-d767-f468d93c93a9"
      },
      "outputs": [],
      "source": [
        "# SQuAD 데이터셋 로드 분석\n",
        "# 스탠포드 대학에서 공개한 질의응답 벤치마크 - Extractive QA 표준\n",
        "squad = load_dataset('squad', split='train[:5000]')\n",
        "squad = squad.train_test_split(test_size=0.2,seed=42)\n",
        "squad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQRYGj-PGsg0",
        "outputId": "04afee2f-6a0a-4d66-f294-3f17fb5e8d4e"
      },
      "outputs": [],
      "source": [
        "squad['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXYt-8x_HDuD",
        "outputId": "7629db80-326a-4af7-cc76-151d18ea99fb"
      },
      "outputs": [],
      "source": [
        "print(squad['train'][0]['context'][:10])\n",
        "print(squad['train'][0]['question'][:10])\n",
        "print(squad['train'][0]['answers']['text'])\n",
        "print(squad['train'][0]['answers']['answer_start'])\n",
        "print(squad['train'][0]['context'][98:98 + len('Neo-Confucian establishment')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6knz_YHpH_Dk"
      },
      "outputs": [],
      "source": [
        "# Fine turnnig\n",
        "# 사전학습만 된모델(QA 헤드는 초기화)  distilbert-base-uncased\n",
        "# 한국어 학습이 가능하지만 성능 보장 못하고 비효율적\n",
        "# distilbert-base-uncased 영어전용 한국어를 전처리할때 어간 및 품사등이 달라서 심하게 왜곡\n",
        "# 한국어면 한국어전용 base에 모델에 파인튜닝을 또는 다국어모델에\n",
        "# mBERT  bert-base-multilingual-cased\n",
        "# klue/bert-base 등등\n",
        "\n",
        "tokenizer =\n",
        "model =\n",
        "device =\n",
        "model = mode.to(device)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
