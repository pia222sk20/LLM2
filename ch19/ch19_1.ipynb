{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upYs8ZJgxkZR"
      },
      "outputs": [],
      "source": [
        "# Extractive QA  : 책에서 문제의 답을 찾는다\n",
        "# 각 단어가 답의 시작일 확률 계산  start_logits\n",
        "# 각 단어가 답의 끝일 확률 계산    end_logits\n",
        "# 가장 확률이 높은 구간 선택       argmax\n",
        "\n",
        "# Extractive QA 시각화\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQw9muQpy4_F"
      },
      "outputs": [],
      "source": [
        "# 모델 로드\n",
        "MODEL_NAME = 'distilbert-base-cased-distilled-squad'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8efNKMe0WO-"
      },
      "outputs": [],
      "source": [
        "# question = \"What is the capital of France?\"\n",
        "# context = \"Paris is the capital and largest city of France. The city has a population of 2.1 million.\"\n",
        "question = 'What is the new peace?'\n",
        "context = '''\n",
        "A new peace proposal for Ukraine drafted by the Trump administration could envision the country ceding the eastern Donbas region and limiting the size of its military in exchange for security guarantees from the United States, according to a Western official familiar with the ideas under discussion.\n",
        "\n",
        "US officials said the plan was still being worked on, and that any final agreement would require concessions from both sides, not just Ukraine. Some of the points being circulated now – including some that appear weighted toward Moscow’s demands – are not final, officials said, and will almost certainly evolve. During a Thursday afternoon briefing, the White House press secretary said the plan remained “in flux.”\n",
        "\n",
        "After meeting a top US military official in Kyiv on Thursday, Ukrainian President Volodymyr Zelensky agreed to work with the Trump administration on the new plan, saying in a social media post that he was prepared for “constructive, honest and swift work” to achieve peace.\n",
        "\n",
        "The 28-point plan, which President Donald Trump has reviewed and supports, is the White House’s latest attempt to bring Russia’s war in Ukraine to an end. Some of the proposal’s provisions — including territorial concessions in areas not currently held by Russia — have previously been nonstarters with the Ukrainians. But US officials see a new window of opportunity to restart peace discussions.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTr9fJDM0iBK"
      },
      "outputs": [],
      "source": [
        "# 토크나이제이션\n",
        "inputs = tokenizer(question,context,return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "3YLAFdVw02dc",
        "outputId": "8d7e652b-7b29-4dd6-d2b8-7931969a05f2"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(inputs['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyuJdlVz2Duw",
        "outputId": "4f464c08-3599-4e15-cf1e-0cfe39566522"
      },
      "outputs": [],
      "source": [
        "# 토큰 리스트\n",
        "tokens = tokenizer.convert_ids_to_tokens( inputs['input_ids'][0] )\n",
        "print(tokens[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZFEVfQ51QlQ",
        "outputId": "e10efece-ebf5-45ef-8799-bdcff7712ba9"
      },
      "outputs": [],
      "source": [
        "# 예측\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho_vxYJA11KZ",
        "outputId": "7a28f796-1c6f-4263-b5ad-e2ca8979595d"
      },
      "outputs": [],
      "source": [
        "# logits를 확률로 변환\n",
        "start_probs = torch.softmax(outputs.start_logits, dim = -1)[0].numpy()\n",
        "end_probs = torch.softmax(outputs.end_logits, dim = -1)[0].numpy()\n",
        "# 답변 추출\n",
        "answer_start = np.argmax(start_probs)\n",
        "answer_end = np.argmax(end_probs) + 1\n",
        "answer_tokens = tokens[answer_start:answer_end]\n",
        "answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
        "\n",
        "print(f'모델의 답변 : {answer}')\n",
        "print(f'시작위치 : {answer_start}  토큰 : {tokens[answer_start]}')\n",
        "print(f'종료위치 : {answer_end}  토큰 : {tokens[answer_end-1]}')\n",
        "print(f'신뢰도 : {start_probs[answer_start] * end_probs[answer_end-1]:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_aJfJm34VH1",
        "outputId": "d948cdba-1c99-4de0-8a0e-50162e84977e"
      },
      "outputs": [],
      "source": [
        "# 상위 5개 후보출력\n",
        "# 시작위치 상위 5개\n",
        "top_start = np.argsort(-start_probs)[:5]\n",
        "for i,index in enumerate(top_start,1):\n",
        "  print(f'시작위치 : {i}  토큰 : {tokens[index]} 확률 : {start_probs[index]}')\n",
        "# 종료위치 상위 5개\n",
        "print()\n",
        "top_end = np.argsort(-end_probs)[:5]\n",
        "for i,index in enumerate(top_end,1):\n",
        "  print(f'종료위치 : {i}  토큰 : {tokens[index]} 확률 : {end_probs[index]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew-xq6_h8UrB",
        "outputId": "d00652ce-d40b-411c-ca7e-bd70d61f8fcc"
      },
      "outputs": [],
      "source": [
        "len(start_probs), len(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "4oKs3MjD7xR1",
        "outputId": "9d6cd691-e00a-4be0-a419-6e2b083c7875"
      },
      "outputs": [],
      "source": [
        "fig, (ax1,ax2)  = plt.subplots(2,1,figsize=(15,10))\n",
        "ax1.bar(range(len(tokens)),start_probs)\n",
        "ax2.bar(range(len(tokens)),end_probs)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fziro30z89Rd"
      },
      "outputs": [],
      "source": [
        "# 결론 : 확률이 고르게 분산 -> 답을 못찾은 경우, 특정구간에 집중되면 확신있는 답을 찾음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t012xpfW_RLF"
      },
      "source": [
        "offset mattping : 토큰단위로 찾다보면 단어가 분리되어서 자연스럽지 못하기 때문에 문자위치로 변환하는 과정을 거쳐야 자연스러운 문장이 나온다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytkJS3Og_QtH"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "문맥 : Paris is the capital of France.\n",
        "       012345678901234  <- 문자 인덱스\n",
        "토큰 : ['Paris','is','the','capital','of','France','.']\n",
        "          0       1     2     3         <-토큰인덱스\n",
        "'''\n",
        "# 모델은 토큰인덱스 로 작동(3번 토큰  'capital')\n",
        "# 답변위치는 문자인덱스 (13번째 문자부터 'capital' 시작)\n",
        "offset_mapping = [\n",
        "    (0,5),   # 토큰 0: \"Paris\"는 문자 0 ~ 5\n",
        "    (6,8),   # 토큰 1 : is 는 문자 6 ~ 8\n",
        "    (9,12),\n",
        "    (13,20)\n",
        "]\n",
        "# 활용\n",
        "# 문자위치 -> 토큰위치 : Fine-tuning시 답변 레이블 생성\n",
        "# 토큰위치 -> 문자위치 : 예측 결과를 원문에 매칭"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW_2YrwfKvoR",
        "outputId": "23d013a1-2376-45d7-f3a0-83f6760cd7f5"
      },
      "outputs": [],
      "source": [
        "# 토큰위치 <-> 문자위치 변환\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "question = \"What is AI?\"\n",
        "context = \"Artificial Intelligence (AI) is the simulation of human intelligence in machines.\"\n",
        "inputs =  tokenizer(\n",
        "    question,\n",
        "    context,\n",
        "    return_tensors = 'pt',\n",
        "    return_offsets_mapping = True\n",
        ")\n",
        "# 토큰리스트\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "offset_mapping =  inputs['offset_mapping'][0].tolist()\n",
        "# 전체 텍스트(질문 + 문맥)\n",
        "full_text = question + context\n",
        "# 토큰별 위치 매핑\n",
        "print(f\"{'인덱스':<8}{'토큰':<25}{'문자위치':<18}{'원문매칭'}\")\n",
        "for idx, (token, (start, end)) in enumerate(zip(tokens, offset_mapping)):\n",
        "  if start == end == 0:  # 특수 토큰\n",
        "      matched_text = \"[특수 토큰]\"\n",
        "      position = \"N/A\"\n",
        "  else:\n",
        "      # 원래 텍스트에서 추출\n",
        "      matched_text = full_text[start:end]\n",
        "      position = f\"({start:3d}, {end:3d})\"\n",
        "\n",
        "  # 답변 영역 하이라이트\n",
        "  highlight = \"\" if \"AI\" in token or \"Intelligence\" in token else \"  \"\n",
        "  print(f\"{idx:<8} {token:<25} {position:<18} '{matched_text}' {highlight}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE-pXaVkNWZ-",
        "outputId": "9dde873f-a77e-4dd4-a963-1000414e80f1"
      },
      "outputs": [],
      "source": [
        "# 실제 답변 위치\n",
        "answer = 'Artificial Intelligence'\n",
        "# 문맥에서 답변의 문자 위치 찾기\n",
        "answer_start_char = context.index(answer)\n",
        "answer_end_char = answer_start_char + len(answer)\n",
        "# 문자위치 -> 토큰위치 변환\n",
        "answer_start_token = None\n",
        "answer_end_token = None\n",
        "# 질문부분 건너뛰기  (sequence_id)\n",
        "sequence_id = inputs.sequence_ids(0)\n",
        "context_start_idx = sequence_id.index(1)  # 첫번재 문맥시작\n",
        "# 문맥에서 절대 위치를 계산하기 위해 질문 길이 보정\n",
        "qeustion_length = len(question) + 1 # +1 은 공백\n",
        "abs_answer_start = answer_start_char + qeustion_length\n",
        "abs_answer_end = answer_end_char + qeustion_length\n",
        "print(f'질문 길이 보정 : +(question_length)')\n",
        "print(f'절대 문자 위치: {abs_answer_start} ~ {abs_answer_end}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A1p-sLfOMTY",
        "outputId": "33cfe73d-4ed1-4d28-f199-26e465361ec5"
      },
      "outputs": [],
      "source": [
        "for idx in range(context_start_idx, len(offset_mapping)):\n",
        "  start, end = offset_mapping[idx]\n",
        "  if start == end == 0:  # 특수 토큰 무시\n",
        "      continue\n",
        "  # 답변 시작 토큰 찾기\n",
        "  if answer_start_token is None and end > abs_answer_start:\n",
        "      answer_start_token = idx\n",
        "      print(f\"    시작 토큰 발견!\")\n",
        "      print(f\"     인덱스: {idx}\")\n",
        "      print(f\"     토큰: '{tokens[idx]}'\")\n",
        "      print(f\"     오프셋: ({start}, {end})\")\n",
        "      print()\n",
        "\n",
        "  # 답변 종료 토큰 찾기\n",
        "  if answer_end_token is None and start >= abs_answer_end:\n",
        "      answer_end_token = idx - 1\n",
        "      print(f\"    종료 토큰 발견!\")\n",
        "      print(f\"      인덱스: {idx - 1}\")\n",
        "      print(f\"      토큰: '{tokens[idx-1]}'\")\n",
        "      print(f\"      오프셋: {offset_mapping[idx-1]}\")\n",
        "      break\n",
        "\n",
        "  print(\"\\n\" + \"=\"*80)\n",
        "  print(\"최종 결과\")\n",
        "  print(\"=\"*80)\n",
        "\n",
        "  if answer_start_token and answer_end_token:\n",
        "    print(f\"\\n 변환 성공!\")\n",
        "    print(f\"   토큰 위치: {answer_start_token} ~ {answer_end_token}\")\n",
        "    print(f\"   토큰 리스트: {tokens[answer_start_token:answer_end_token+1]}\")\n",
        "\n",
        "    # 역변환 확인\n",
        "    reconstructed = tokenizer.convert_tokens_to_string(\n",
        "        tokens[answer_start_token:answer_end_token+1]\n",
        "    )\n",
        "    print(f\"   복원된 텍스트: '{reconstructed}'\")\n",
        "    print(f\"   원본 텍스트: '{answer}'\")\n",
        "\n",
        "    if answer.lower() in reconstructed.lower():\n",
        "        print(f\"\\n   검증 성공! 완벽하게 매칭됩니다.\")\n",
        "    else:\n",
        "        print(f\"\\n   부분 일치 (토크나이제이션으로 인한 차이)\")\n",
        "  else:\n",
        "   print(\"\\n 변환 실패 - 답변을 찾을 수 없습니다\")\n",
        "\n",
        "\n",
        "    #  Offset Mapping이란?\n",
        "    #    각 토큰이 원본 텍스트의 어느 위치에 해당하는지 기록\n",
        "\n",
        "    #  형식:\n",
        "    #    [(start_char, end_char), ...]\n",
        "    #    - start_char: 토큰 시작 문자 위치\n",
        "    #    - end_char: 토큰 종료 문자 위치 (exclusive)\n",
        "\n",
        "    # 변환 방법:\n",
        "    #    1. 문자 위치 → 토큰 위치\n",
        "    #       - offset_mapping을 순회\n",
        "    #       - 문자 위치가 offset 범위 내에 있는 토큰 찾기\n",
        "\n",
        "    #    2. 토큰 위치 → 문자 위치\n",
        "    #       - offset_mapping[토큰_인덱스] 직접 참조\n",
        "\n",
        "    # 주의사항:\n",
        "    #    - 특수 토큰은 (0, 0)으로 표시\n",
        "    #    - truncation으로 잘린 부분은 offset 없음\n",
        "    #    - Fine-tuning 시 필수적으로 사용!\n",
        "\n",
        "    # 활용:\n",
        "    #    - SQuAD 데이터 전처리: 답변 문자 위치 → 토큰 위치\n",
        "    #    - 예측 결과 해석: 토큰 위치 → 원문 매칭\n",
        "    #    - 답변 검증: 예측한 토큰이 실제 답변과 일치하는지 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "FV20phlZQTCE",
        "outputId": "fe2e4187-e902-4f79-ec80-d0e35fc21922"
      },
      "outputs": [],
      "source": [
        "# SQuAD 데이터 전처리\n",
        "# SQuAD 모델이 이해할 수 있는 형식으로 바꾸는 과정에 대한 이해\n",
        "'''\n",
        "{\n",
        "  'question':'When was ......?\",\n",
        "  'context' : 'The Eiffel Tower......\",\n",
        "  'asnwer':{\n",
        "    'text':[\"1889\"],\n",
        "    'asnwer_start':[31]  <- 문자위치\n",
        "  }\n",
        "}\n",
        "'''\n",
        "# 1. 토크나이제이션\n",
        "# [CLS] When was ... [SEP] the eiffel tower...... [SEP]\n",
        "\n",
        "# 2.답변 문자 위치 확인\n",
        "answer_start_char = 31\n",
        "answer_end_char = 35 # (31 + len('1889'))\n",
        "# 3. sequence_ids로 문맥 범위 찾기\n",
        "context_range = [10,45] # 토큰10번 ~ 45번이 문맥\n",
        "# 4 offset_mapping 으로 토큰위치 변환\n",
        "aswer_start_token = 18  # (토큰18번 = 1889의  시작)\n",
        "aswer_end_token = 19 # (토큰19번 = 1889의  끝)\n",
        "# 5 검증  답변이 문맥 내-->yes  , truncate로 잘리지 않음->yes\n",
        "# 6 최종 학습데이터 생성\n",
        "'''\n",
        "      {\n",
        "        'input_ids':....\n",
        "        'attention_mask':....\n",
        "        'start_positions':18,\n",
        "        'end_positions':19\n",
        "      }\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc1FY2SZTfwZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
