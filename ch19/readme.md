# 트랜스포머 모형을 이용한 질의 응답


- 질의 응답(Question Answering) 시스템의 개념과 종류 이해
- Extractive QA와 Generative QA의 차이점 파악
- BERT 기반 질의응답 모델 활용
- SQuAD 데이터셋을 이용한 미세조정 학습
- 한글 질의응답 시스템 구현

---

## 질의 응답 시스템의 이해

### 질의 응답(QA)이란?
주어진 문맥(Context)에서 질문(Question)에 대한 답변(Answer)을 찾는 NLP 작업

### QA 시스템의 종류

#### 1. Extractive QA (추출형)
- **방식**: 주어진 문맥에서 답변을 **그대로 추출**
- **특징**: 답변이 반드시 문맥 내에 존재
- **예시**:
  - 문맥: "서울은 대한민국의 수도이다"
  - 질문: "대한민국의 수도는?"
  - 답변: "서울" ← 문맥에서 추출

#### 2. Generative QA (생성형)
- **방식**: 문맥을 이해하고 새로운 답변을 **생성**
- **특징**: 답변이 문맥에 없어도 가능
- **예시**:
  - 문맥: "서울의 인구는 1000만명이다"
  - 질문: "서울은 큰 도시인가?"
  - 답변: "네, 1000만명의 인구를 가진 대도시입니다" ← 생성

**💡 실습은 Extractive QA에 집중합니다**

---

## 파이프라인을 이용한 질의 응답

### 기본 구조
```
입력: Question + Context
  ↓
모델: BERT/DistilBERT
  ↓
출력: Answer (시작 위치, 종료 위치, 신뢰도)
```

### 주요 특징
- 기본 모델: `distilbert-base-cased-distilled-squad`
- SQuAD 데이터셋으로 사전학습된 모델
- 영어 문서에 최적화

### 출력 정보
- `answer`: 추출된 답변 텍스트
- `score`: 신뢰도 점수 (0~1)
- `start`: 답변 시작 위치 (문자 인덱스)
- `end`: 답변 종료 위치 (문자 인덱스)

---

## 자동 클래스를 이용한 질의 응답

### BERT의 QA 작동 원리

1. **입력 구성**
   ```
   [CLS] 질문 [SEP] 문맥 [SEP]
   ```

2. **모델 출력**
   - `start_logits`: 각 토큰이 답변 시작 위치일 확률
   - `end_logits`: 각 토큰이 답변 종료 위치일 확률

3. **답변 추출**
   - start_logits에서 argmax → 시작 위치
   - end_logits에서 argmax → 종료 위치
   - 해당 토큰들을 텍스트로 변환

### 신뢰도가 낮은 경우
- 문맥에 답이 없는 경우
- 질문이 모호한 경우
- 모델이 학습하지 않은 도메인

---

## Trainer를 이용한 미세조정 학습

### SQuAD 데이터셋
- **Stanford Question Answering Dataset**
- 100,000+ 질문-답변 쌍
- Wikipedia 기반 문맥
- 구조:
  ```python
  {
    "context": "긴 문맥 텍스트...",
    "question": "질문?",
    "answers": {
      "text": ["답변"],
      "answer_start": [123]  # 문맥 내 시작 위치
    }
  }
  ```

### 데이터 전처리 핵심
1. **질문 + 문맥 토크나이제이션**
2. **답변 위치를 토큰 인덱스로 변환**
   - 문자 위치 → 토큰 위치
   - `offset_mapping` 활용
3. **문맥을 벗어난 답변 처리**
   - 답변이 truncate되면 (0, 0) 설정

### 학습 과정
- 입력: 질문 + 문맥
- 레이블: 답변 시작/종료 토큰 위치
- 손실 함수: Cross-Entropy (시작/종료 각각)

---

## 한글 질의 응답

### KoELECTRA 모델
- **개발**: monologg
- **기반**: ELECTRA (Google)
- **학습 데이터**: KorQuAD (한국어 SQuAD)
- **특징**: 
  - 경량화 (small-v2)
  - 384 토큰 최대 길이
  - 높은 정확도

### KorQuAD 데이터셋
- 한국 Wikipedia 기반
- 70,000+ 질문-답변 쌍
- 다양한 주제 (역사, 과학, 문화 등)

---

## 요약

| 구분 | Extractive QA | Generative QA |
|------|---------------|---------------|
| 답변 출처 | 문맥에서 추출 | 모델이 생성 |
| 정확성 | 높음 (문맥 기반) | 변동적 |
| 유연성 | 낮음 | 높음 |
| 모델 예 | BERT, ELECTRA | T5, GPT |
| 사용 사례 | 문서 검색, FAQ | 대화형 AI |

---


### 언제 Extractive QA를 사용?
**적합한 경우**
- 정확한 사실 정보 추출
- 법률, 의료 문서 분석
- 계약서, 매뉴얼 검색
- 규정 준수 확인

**부적합한 경우**
- 추론이 필요한 질문
- 의견이나 감정 분석
- 요약이 필요한 경우
- 다중 문서 통합 답변

### 성능 향상 방법
1. **도메인 데이터로 Fine-tuning**
2. **문맥 길이 최적화** (너무 길면 truncate)
3. **질문 표현 다양화** (데이터 증강)
4. **Ensemble** (여러 모델 결합)

---

## 다음주 주제

- **RAG (Retrieval-Augmented Generation)**: 검색 + 생성 결합
- **Open-domain QA**: 문맥 없이 지식 기반 답변
- **Multi-hop QA**: 여러 단계 추론 필요한 질문