{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLmRdEzRlw2f"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "the cat sat on the mat\n",
        "RNN 계열  : 왼쪽->오른쪽  멀리떨어진 단어들은 서로 영향을 주고 받기 어려움\n",
        "\n",
        "The cat that the boy who lived here adopted is sleeping\n",
        "cat VS sleeping\n",
        "\n",
        "self-attention\n",
        "Q : 찾고 싶은 정보\n",
        "K : 가진 정보\n",
        "V : 최종 전달할 정보\n",
        "\n",
        "비교대상       유사도            의미\n",
        "cat vs the     낮음            the 의미없음\n",
        "cat vs cat     높음            자기자신\n",
        "cat vs sat     중간            동사와 연결\n",
        "cat vs on      낮음            on 전치사...\n",
        "cat vs mat     낮음            의미적으로 멀다\n",
        "\n",
        "softmax로 중요도 확률처럼 변경  유사도를 가중치로 변환\n",
        "단어        가중치\n",
        "the          0.05\n",
        "cat           0.6\n",
        "sat           0.3\n",
        "mat          0.05\n",
        "\n",
        "cat이 보는 시점은\n",
        "Query(cat) -> compare with -> key(the) ->key(cat) ->key(sat)\n",
        "\n",
        "가중치\n",
        "the : 01   cat:  0.7   sat : 0.2\n",
        "출력 : 0.1*value(the) + .....\n",
        "\n",
        "RNN 순차처리\n",
        "self-attention  병열처리\n",
        "\n",
        "다중의미처리\n",
        "river bank   river를 강하게 참조\n",
        "bank loan    loan을 강하게 참조\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "013o-PmSpM8E",
        "outputId": "2dec4b07-996a-4530-b0c8-09ebb0ad0c2d"
      },
      "outputs": [],
      "source": [
        "# self-attention 시각화\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "words = ['cat','fish','like']  # 고양이가 생선을 좋아한다\n",
        "# 가상의 attention 가중치\n",
        "# 각 행은 해당 단어가 다른단어들에게 주목하는 정도\n",
        "attention_weight = np.array([\n",
        "    [0.7,0.2,0.1],  # 고양이는 자가자신에게 가장 높은 가중치\n",
        "    [0.3,0.5,0.2],  #\n",
        "    [0.4,0.3,0.3]\n",
        "])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "im = ax.imshow(attention_weight, cmap='YlOrRd')\n",
        "\n",
        "ax.set_xticks(range(len(words)))\n",
        "ax.set_yticks(range(len(words)))\n",
        "ax.set_xticklabels(words)\n",
        "ax.set_yticklabels(words)\n",
        "\n",
        "ax.set_xlabel('key')\n",
        "ax.set_ylabel('query')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixI08ZrnpNv1"
      },
      "outputs": [],
      "source": [
        "# Beam Search\n",
        "# 문장을 생성할때 다음에 나올단어는 수천~수만개가 될수 있는데. 이걸 경우의수로 따지면..... X\n",
        "# 상위 N개의 후보만 유지  , N을 beam size\n",
        "# beam size = 1 매번 가장 좋은것만 선택(Greedy)\n",
        "# beam size = 4 4개의 가능성을 동시에 탐색"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU2qGUBrsvH8",
        "outputId": "77d174e5-29c5-4c68-959e-b34a978bdb4e"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import time\n",
        "MODEL_NAME = 't5-small'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "text = \"\"\"summarize: The Amazon rainforest is the world's largest tropical rainforest.\n",
        "  It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries.\n",
        "  The Amazon is home to millions of species of plants and animals, many of which are found nowhere else on Earth.\n",
        "  However, deforestation poses a significant threat to this vital ecosystem.\"\"\"\n",
        "\n",
        "print('원본 : ')\n",
        "print(text.replace('summarize:',''))\n",
        "inputs = tokenizer(text, return_tensors='pt',max_length=512,truncation=True).to(device)\n",
        "# 다양한 beam size 실험\n",
        "beam_sizes = [1,2,4,8]\n",
        "results = []\n",
        "for num_beams in beam_sizes:\n",
        "  print(f'beam size : {num_beams}')\n",
        "  start_time = time.time()\n",
        "  outputs = model.generate(\n",
        "      **inputs,\n",
        "      num_beams = num_beams,\n",
        "      max_length=60,\n",
        "      min_length=20,\n",
        "      early_stopping = True,\n",
        "      no_repeat_ngram_size = 3,\n",
        "      num_return_sequences=1\n",
        "  )\n",
        "  elapsed_time = time.time() - start_time\n",
        "  summary = tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
        "  results.append((num_beams,summary,elapsed_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2noqRmno0DlH",
        "outputId": "0f1b0516-2e8b-49d1-e354-573a071c73c1"
      },
      "outputs": [],
      "source": [
        "for num_beams,summary,elapsed_time in results:\n",
        "  print(f'측정시간 : {elapsed_time}')\n",
        "  print(f'beam size : {num_beams}')\n",
        "  print(summary)\n",
        "  print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
